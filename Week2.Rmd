---
title: "Summary"
author: "Jinkwan Hong"
date: "2019년 2월 15일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is a part of Data Science Specialization Course provided by Coursera and John's Hopkins University. 

Goal:  

* Does the link lead to an HTML page describing the exploratory analysis of the training data set?
* Has the data scientist done basic summaries of the three files? Word counts, line counts and basic data tables?
* Has the data scientist made basic plots, such as histograms to illustrate features of the data?
* Was the report written in a brief, concise style, in a way that a non-data scientist manager could appreciate?

## Resources

### Information

[Natural language processing Wikipedia page](https://en.wikipedia.org/wiki/Natural_language_processing)  
[Text mining infrastucture in R](http://www.jstatsoft.org/v25/i05/)  
[CRAN Task View: Natural Language Processing](http://cran.r-project.org/web/views/NaturalLanguageProcessing.html)  
[Coursera course on NLP (not in R)](https://www.coursera.org/course/nlp)  
#[Software Quality - TDD and unit testing in R using the 'testthat' package](https://pparacch.github.io/2017/05/18/test_driven_development_in_r.html)

### Data

[Capstone Dataset](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip)

### Packages

* testthat


## Tasks

[ ] Obtaining the data - Can you download the data and load/manipulate it in R?  
  load 
  [ ]Tokenization - identifying appropriate tokens such as words, punctuation, and numbers. Writing a function that takes a file as input and returns a tokenized version of it.
  [ ] Profanity filtering - removing profanity and other words you do not want to predict.
[ ] Familiarizing yourself with NLP and text mining - Learn about the basics of natural language processing and how it relates to the data science process you have learned in the Data Science Specialization.  

[ ] Exploratory analysis - perform a thorough exploratory analysis of the data, understanding the distribution of words and relationship between the words in the corpora.

[ ] Understand frequencies of words and word pairs - build figures and tables to understand variation in the frequencies of words and word pairs in the data.

[ ] Build basic n-gram model - using the exploratory analysis you performed, build a basic n-gram model for predicting the next word based on the previous 1, 2, or 3 words.

[ ] Build a model to handle unseen n-grams - in some cases people will want to type a combination of words that does not appear in the corpora. Build a model to handle cases where a particular n-gram isn't observed.


## Summary

## Result(Verbose)

## Lesson Learned

## Appendix

